<!DOCTYPE html>
<html>
<head>
<title>Appcanary: security</title>
<meta content='&lt;a href="https://appcanary.com"&gt;Appcanary&lt;/a&gt; makes sure you never run vulnerable software in your apps.&lt;br/&gt;Subscribe to our &lt;a href="https://appcanary.us10.list-manage.com/subscribe?u=303b378f377508300c0b5469a&amp;id=dc58e8f56f"&gt;newsletter&lt;/a&gt;!' name='description'>
<meta charset='utf-8'>
<meta content='width=device-width, initial-scale=1.0' name='viewport'>
<meta content='IE=edge' http-equiv='X-UA-Compatible'>
<meta content='True' name='HandheldFriendly'>
<meta content='Appcanary' property='og:site_name'>
<meta content='website' property='og:type'>
<meta content='security' property='og:title'>
<meta content='&lt;a href="https://appcanary.com"&gt;Appcanary&lt;/a&gt; makes sure you never run vulnerable software in your apps.&lt;br/&gt;Subscribe to our &lt;a href="https://appcanary.us10.list-manage.com/subscribe?u=303b378f377508300c0b5469a&amp;id=dc58e8f56f"&gt;newsletter&lt;/a&gt;!' property='og:description'>
<meta content='http://blog.appcanary.com/tag/security.html' property='og:url'>
<meta content='http://blog.appcanary.com/images/appcanary.png' property='og:image'>
<meta content='summary' name='twitter:card'>
<meta content='security' name='twitter:title'>
<meta content='&lt;a href="https://appcanary.com"&gt;Appcanary&lt;/a&gt; makes sure you never run vulnerable software in your apps.&lt;br/&gt;Subscribe to our &lt;a href="https://appcanary.us10.list-manage.com/subscribe?u=303b378f377508300c0b5469a&amp;id=dc58e8f56f"&gt;newsletter&lt;/a&gt;!' name='twitter:description'>
<meta content='http://blog.appcanary.com/tag/security.html' name='twitter:url'>
<meta content='http://blog.appcanary.com/images/appcanary.png' name='twitter:image:src'>
<link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" />
<link href="/images/favicon.ico" rel="icon" type="image/ico" />
<link href="../stylesheets/application.css" rel="stylesheet" />
<script src="//use.typekit.net/dkz5zwp.js"></script>
<script>try{Typekit.load({ async: false });}catch(e){}</script>

</head>
<body class='post-template home-post-template nav-closed'>
<div class='topbar'></div>
<div class='nav'>
<h3 class='nav-title'>Menu</h3>
<a class='nav-close' href='#'>
<span class='hidden'>Close</span>
</a>
<ul>
<li class='nav-home' role='presentation'>
<a href='/'>Home</a>
</li>
<li class='nav-archive' role='presentation'>
<a href='archive.html'>Archive</a>
</li>
<li class='nav-github' role='presentation'>
<a href='https://github.com/appcanary'>Github</a>
</li>
</ul>
<a class='subscribe-button icon-feed' href='/tag/security.htmlfeed.xml'>Subscribe</a>
</div>
<span class='nav-cover'></span>

<div class='site-wrapper'>
<header class='main-header no-cover tag-head'>
<nav class='main-nav overlay clearfix'>
<a class='blog-logo' href='/'>
<img alt="Appcanary" src="../images/appcanary.png" />
</a>
</nav>
<div class='vertical'>
<div class='main-header-content inner'>
<h1 class='page-title'>security</h1>
<h2 class='page-description'>A 3-post collection</h2>
</div>
</div>
</header>
<main class='content' id='content' role='main'>
<div class='extra-pagination inner'>
<nav class='pagination' role='pagination'>
<span class='page-number'>Page 1 of 1</span>
</nav>

</div>
<article class='post'>
<header class='post-header'>
<h1 class='post-title'><a href="../2016/vikhal-morris.html">Morris & badBIOS, 25 years in 2 worms: ViHKAL #2</a></h1>
<section class='post-meta'>
</section>
</header>
<section class='post-content'>
<p>Paranoia is natural for security practitioners. </p>

<p>Hacking can feel like being initiated into a secret society of wizards.
Once you&rsquo;re in, you get access to an
<a href="https://docs.google.com/presentation/d/1Sv8IHkBtBEXjSW7WktEYg4EbAUHtVyXIZBrAGD3WR5Y/edit?pref=2&pli=1#slide=id.p" target="_blank">addictive drug</a>
that gives you super powers. But there are other wizards out there; some are good
but many practice black magic. And the NSA&rsquo;s school of the dark arts has a seemingly
unlimited budget. </p>

<p>It&rsquo;s natural to get a little paranoid. Experience shows you
that with the right incantation you can turn crashes into working exploits. It
follows that every time your computer crashes there could be someone in the
shadows, chanting the right incantation. The paranoia can be all-consuming;
just because you&rsquo;re paranoid doesn&rsquo;t mean they&rsquo;re not <a href="http://www.nytimes.com/2011/07/02/opinion/02hotchner.html?_r=0" target="_blank">out to get you</a>.</p>

<p>In October 2013, a well known computer security expert named Dragos Ruiu came
out with a <a href="http://arstechnica.com/security/2013/10/meet-badbios-the-mysterious-mac-and-pc-malware-that-jumps-airgaps/" target="_blank">story</a>. He found that his computers had been behaving oddly, and that the symptoms he was seeing were impossible to eradicate. This was some kind of worm, since the behavior would
replicate across <a href="https://en.wikipedia.org/wiki/Air_gap_(networking)" target="_blank">air gapped</a> computers in his lab. He theorized that he
was infected with a super advanced piece of malware that lived in the BIOS and
could spread by sending ultrasonic frequencies from speaker to
microphone, undetectable to the human ear. It looked like
the work of the NSA or someone equally omnipotent. He dubbed it badBIOS. </p>

<p>Everything Dragos claimed badBIOS could do is at least possible, and most security folks know this. Malware in the BIOS is feasible, and beyond being a <a href="https://www.wired.com/2015/03/researchers-uncover-way-hack-bios-undermine-secure-operating-systems/" target="_blank">research</a> topic, it&rsquo;s something we <a href="https://www.schneier.com/blog/archives/2015/02/the_equation_gr.html" target="_blank">know</a> the <a href="http://www.spiegel.de/international/world/catalog-reveals-nsa-has-back-doors-for-numerous-devices-a-940994.html" target="_blank">NSA does</a>. In fact, because of the hype, <a href="https://github.com/Katee/quietnet" target="_blank">many</a> <a href="https://www.anfractuosity.com/projects/ultrasound-networking/" target="_blank">people</a> developed ultrasound networking libraries just to demonstrate how viable it is. </p>

<p>Dragos Ruiu imaged his computer and made a lot of data available to the
community for peer review, but unfortunately no credible researcher<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup> has publicly confirmed his findings. Maybe there was something going on. Maybe he was seeing patterns in the noise. Either way, it says something about the world today that when you&rsquo;re a security expert and your computer starts behaving weirdly, the obvious culprit is the NSA.</p>

<p>It made me think of a different worm, from a more innocent time.</p>

<p><img alt="Morris Worm" src="../images/morris_worm.jpg" /></p>

<h2>The Morris Worm</h2>

<p>It&rsquo;s November 2nd 1988, almost exactly 25 years before badBIOS became a
hashtag. Robert Tappan Morris, a graduate student at Cornell, executes some
code he&rsquo;d been working on and goes to dinner. The aftermath was a
self-replicating computer worm that infected 10% of the Internet<sup id="fnref2"><a href="#fn2" rel="footnote">2</a></sup> at
the time &mdash; a whopping 6,000 computers!</p>

<p>Morris claimed that he wrote his program to map the size of the Internet. And
indeed, each infection would send a byte to a machine in Berkeley
(hiding the trail to Morris, in Cornell, as the author). Unfortunately,
there was a bug that caused it to propagate too aggressively: it infected the same
computer multiple times, which resulted in a denial of service attack across the
whole Internet. Furthermore, the code to report infections had a bug in it. It tried to
send a UDP packet over a TCP socket, making it useless for reporting the Internet&rsquo;s size.</p>

<p>An alternative explanation is that Morris was trying to bring to wider attention
some long-standing bugs in the Internet. As Morris&rsquo; friend and future co-founder <a href="http://www.nytimes.com/1988/11/07/us/computer-invasion-back-door-ajar.html" target="_blank">put it</a>, in classic pg<sup id="fnref3"><a href="#fn3" rel="footnote">3</a></sup> style:</p>

<blockquote>
<p>Mr. Graham, who has known the younger Mr. Morris for several years, compared
his exploit to that of Mathias Rust, the young German who flew light plane
through Soviet air defenses in May 1987 and landed in Moscow.</p>

<p>&ldquo;It&rsquo;s as if <a href="https://en.wikipedia.org/wiki/Mathias_Rust" target="_blank">Mathias Rust</a> had not just flown into Red Square, but built
himself a stealth bomber by hand and then flown into Red Square,&rdquo; he said.</p>
</blockquote>

<h3>What did the Morris Worm actually do?</h3>

<p>The Morris Worm<sup id="fnref4"><a href="#fn4" rel="footnote">4</a></sup> exploited three separate vulnerabilities. It guessed
passwords for <code>rsh</code>/<code>rexec</code>, it exploited a debug-mode backdoor in sendmail and it used &ldquo;one
very neat trick&rdquo;. I&rsquo;ll go over each of these in detail, and you can find an archive (decompiled and commented) of the code for yourself <a href="https://github.com/arialdomartini/morris-worm" target="_blank">here</a>.</p>

<h4>1. Rsh and Rexec</h4>

<p><code>rsh</code> and <code>rexec</code> are remote shell protocols from the BSD era that are almost
unused today (since supplanted by <code>ssh</code>). <code>rsh</code> can allow passwordless
authentication if coming from a &ldquo;trusted&rdquo; host, which it determines via a list of addresses stored in a global <code>/etc/hosts.equiv</code> or
per-user <code>.rhosts</code> file. When an
<code>rsh</code> request comes from a user of a trusted machine, access is automatically
granted. The worm used this to propagate, searching those two files &mdash; as well as the <code>.forward</code> file, which back then was used to forward your mail around the Internet &mdash; for trusted hosts.</p>

<p>Even in 1988, people knew that leaving <code>rsh</code> open on an untrusted network like
the Internet was a Bad Idea, and so the worm also propagated via <code>rexec</code>.
Now, <code>rexec</code> uses password authentication, but Morris made an intelligent assumption:
people tend to reuse passwords.
Back then, <code>/etc/passwd</code> used to<sup id="fnref5"><a href="#fn5" rel="footnote">5</a></sup> store everyone&rsquo;s encrypted passwords. The
worm shipped with an optimized implementation of
<a href="https://en.wikipedia.org/wiki/Crypt_(Unix)" target="_blank"><code>crypt</code></a> and a dictionary, and went to town. Once it cracked a password, it tried it against
all the likely hosts it could find.</p>

<h4>2. Sendmail&rsquo;s Backdoor</h4>

<p>In the absence of any friendly hosts, the Morris Worm would then exploit a
backdoor in <a href="https://en.wikipedia.org/wiki/Sendmail" target="_blank">Sendmail</a>. You see, Sendmail had a &ldquo;debug&rdquo; mode that allowed anyone to route an
email to any process, including the shell! Ironically, this was <a href="http://www.nytimes.com/1988/11/07/us/computer-invasion-back-door-ajar.html" target="_blank">apparently deliberate</a>:</p>

<blockquote>
<p>Eric Allman, a computer programmer who designed the mail program that Morris
exploited, said yesterday that he created the back door to allow him to fine
tune the program on a machine that an overzealous administrator would not give
him access to. He said he forgot to remove the entry point before the program
was widely distributed in 1985.</p>
</blockquote>

<p>(This wasn&rsquo;t even the first Sendmail backdoor. Sendmail used to ship with &ldquo;wizard mode&rdquo;, where sending the strings &ldquo;WIZ&rdquo; and &ldquo;SHELL&rdquo; gave you a root shell. By the time that Morris was writing his worm, wizard mode was disabled almost everywhere.)</p>

<p>If you&rsquo;re wondering how sendmail could have backdoors like this, it seems that it was somewhat well known. This quote from a <a href="http://securitydigest.org/tcp-ip/archive/1988/11" target="_blank">mail</a> by <a href="https://en.wikipedia.org/wiki/Paul_Vixie" target="_blank">Paul Vixie</a> summarizes the situation.</p>
<pre class="highlight plaintext"><code>From: vixie@decwrl.dec.com (Paul Vixie)
Newsgroups: comp.protocols.tcp-ip,comp.unix.wizards
Subject: Re: a holiday gift from Robert "wormer" Morris
Message-ID: &lt;24@jove.dec.com&gt;
Date: 6 Nov 88 19:36:10 GMT
References: &lt;1698@cadre.dsl.PITTSBURGH.EDU&gt; &lt;2060@spdcc.COM&gt;
Distribution: na
Organization: DEC Western Research Lab
Lines: 15


# the hole [in sendmail] was so obvious that i surmise that Morris
# was not the only one to discover it.  perhaps other less
# reproductively minded arpanetters have been having a field
# 'day' ever since this bsd release happened. 

I've known about it for a long time.  I thought it was common knowledge
and that the Internet was just a darned polite place.  (I think it _was_
common knowledge among the people who like to diddle the sendmail source.)

The bug in fingerd was a big surprise, though.  Overwriting a stack frame
on a remote machine with executable code is One Very Neat Trick.
-- 
Paul Vixie
Work:    vixie@decwrl.dec.com    decwrl!vixie    +1 415 853 6600
Play:    paul@vixie.sf.ca.us     vixie!paul      +1 415 864 7013
</code></pre>

<p>The Internet was a polite place, indeed.</p>

<h4>3. One Very Neat Trick</h4>

<p>The Very Neat Trick that Vixie was talking about is the now-standard
<a href="https://en.wikipedia.org/wiki/Buffer_overflow" target="_blank">stack buffer overflow</a>. It&rsquo;s
fascinating to read contemporary accounts that marvel at the cleverness of a class of
bugs that are now ubiquitous &mdash; although, for me at least, they still haven&rsquo;t
lost their magic<sup id="fnref6"><a href="#fn6" rel="footnote">6</a></sup>.</p>

<p>Here&rsquo;s the main routine from the <code>fingerd</code> of that <a href="http://minnie.tuhs.org/cgi-bin/utree.pl?file=4.3BSD/usr/src/etc/fingerd.c" target="_blank">era</a>:</p>
<pre class="highlight c"><code><span class="n">main</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span> <span class="n">argv</span><span class="p">)</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[];</span>
<span class="p">{</span>
    <span class="k">register</span> <span class="kt">char</span> <span class="o">*</span><span class="n">sp</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">line</span><span class="p">[</span><span class="mi">512</span><span class="p">];</span>
    <span class="k">struct</span> <span class="n">sockaddr_in</span> <span class="n">sin</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">pid</span><span class="p">,</span> <span class="n">status</span><span class="p">;</span>
    <span class="kt">FILE</span> <span class="o">*</span><span class="n">fp</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">av</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>

    <span class="n">i</span> <span class="o">=</span> <span class="k">sizeof</span> <span class="p">(</span><span class="n">sin</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">getpeername</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">sin</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">i</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">fatal</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">"getpeername"</span><span class="p">);</span>
    <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="sc">'\0'</span><span class="p">;</span>
    <span class="n">gets</span><span class="p">(</span><span class="n">line</span><span class="p">);</span>
    <span class="n">sp</span> <span class="o">=</span> <span class="n">line</span><span class="p">;</span>
    <span class="c1">// ... snip ...
</span>    <span class="c1">// build sp into arguments for finger 
</span>    <span class="c1">// and call /usr/ucb/finger via execv before
</span>    <span class="c1">// putchar'ing the result back to stdout
</span>    <span class="k">return</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="p">}</span> 
</code></pre>

<p>If you have experience with reading C code,<sup id="fnref7"><a href="#fn7" rel="footnote">7</a></sup> you may have spotted the
vulnerability. <code>gets(line)</code> reads STDIN and puts the contents into a 512 byte
buffer. This means that sending more than 512 bytes will overwrite the stack
with an attacker-controlled value.</p>

<p>The worm sent 536 bytes of data, which overwrote the
<a href="https://en.wikipedia.org/wiki/Call_stack#Stack_and_frame_pointers" target="_blank">stack frame</a>
of the <code>main</code> function. This allowed Morris to overwrite the pointer to where
<code>main</code> is returning to. He set that pointer to be <em>within</em> the 536 byte buffer
he sent over the network. The beginning of the buffer contained
<a href="https://en.wikipedia.org/wiki/Shellcode" target="_blank">shellcode</a> that called <code>/bin/sh</code>. Game over.</p>

<h2>Aftermath</h2>

<p>Robert Tappan Morris was convicted and sentenced to three years probation, 400
hours of community service and a $10,050 fine (about $20,000 in today&rsquo;s dollars)
plus the cost of his supervision. He then went on to co-found a little startup
called Viaweb. You may have heard the rest of that story.
Today, Morris is a tenured professor at the Computer Science and Artificial
Intelligence Laboratory at MIT and is one of the leaders of the Parallel and
Distributed Systems Groups.</p>

<p>Why did the paranoia around badBIOS make me think of the Morris Worm? If you read contemporary articles about the Morris Worm, they&rsquo;ll sometimes mention, but never emphasize, who Robert Morris&rsquo;s father was. The <a href="https://en.wikipedia.org/wiki/Robert_Morris_(cryptographer)" target="_blank">elder Robert Morris</a> just happened to be a computer security expert. While the young Robert Morris was writing his worm, Robert Morris Sr. was serving as Chief Scientist at the NSA&rsquo;s National Computer Security Center! </p>

<p>The Internet grew up a lot since 1988, and not just in size. In 2013, your computer acting strangely is obviously a NSA-written malware that lives in your BIOS and propagates over sound waves imperceptible to the human ear. In 1988, son of an NSA security executive infects 10% of the Internet with a worm that uses an exotic new exploitation technique called a buffer overflow and&hellip; nothing.</p>

<p>Just to be clear, I&rsquo;m not alleging any conspiracy between father and son, besides perhaps father making some calls after son&rsquo;s arrest. While the Morris worm was likely the first malicious use, buffer overflows were understood as a problem before 1988, if not widely. The way the media narrative handled the NSA connection in 1988 just says a lot about how the world of the Internet changed in 25 years.</p>

<p>As for Dragos Ruiu, he&rsquo;s been quiet about badBIOS since 2013. I&rsquo;m not sure what he&rsquo;s doing these days besides <a href="https://cansecwest.com/" target="_blank">CanSecWest</a>, but in my heart of hearts, I like to picture him playing the saxophone amidst the detritus of his torn up apartment.</p>

<p><a href="https://en.wikipedia.org/wiki/The_Conversation" target="_blank"><img src="../images/the_conversation.jpg"></a></p>

<hr>

<h4>Paying the Bills</h4>

<p>We&rsquo;re trying our best, but we&rsquo;ll only be able to blog about a minuscule percentage of the world&rsquo;s vulnerabilities. And starting with 1988 means we have a lot of catching up to do. How will you ever find about the ones that actually affect you?</p>

<p>Our product, <a href="https://appcanary.com/?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=morris">Appcanary</a>, monitors your apps and servers, and notifies you whenever a new vulnerability is discovered in a package you rely on. </p>

<p><a href="https://appcanary.com/sign_up?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=morris">Sign up</a> today!</p>

<hr>

<p><link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
 #mc<em>embed</em>signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}
 /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
      We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//appcanary.us10.list-manage.com/subscribe/post?u=303b378f377508300c0b5469a&amp;id=dc58e8f56f" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
<div id="mc_embed_signup_scroll">
<label for="mce-EMAIL">Liked this post? Subscribe to our newsletter for more!</label>
<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
<div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_303b378f377508300c0b5469a_dc58e8f56f" tabindex="-1" value=""></div>
<div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
</div>
</form>
</div></p>

<div class="footnotes">
<hr>
<ol>

<li id="fn1">
<p>One of the things I wish that the security industry would do less of is blind appeals to authority, and I hate that I made one here. Unfortunately, I don&rsquo;t have the skills or time to make my own analysis of Ruiu&rsquo;s data, so I just have to trust the Thought Leaders on this one. &nbsp;<a href="#fnref1" rev="footnote">&#8617;</a></p>
</li>

<li id="fn2">
<p>The 60,000 computer-strong Internet was of course one of many networks at the time. The Internet was the one that was global and used TCP/IP &mdash; the Internet protocols. Therein lies the pedant&rsquo;s case against the <a href="https://twitter.com/APStylebook/status/716279065888563200" target="_blank">AP&rsquo;s capitalization</a> of the word &ldquo;Internet&rdquo;.&nbsp;<a href="#fnref2" rev="footnote">&#8617;</a></p>
</li>

<li id="fn3">
<p>Disclosure time: years after giving that quote, Paul Graham and Robert Morris went on to found Y Combinator along with Jessica Livingston and Trevor Blackwell. YC in turn is an investor in <a href="https://www.appcanary.com">Appcanary</a>. Robert Morris and I have never met, though we did once meet with Paul Graham. &nbsp;<a href="#fnref3" rev="footnote">&#8617;</a></p>
</li>

<li id="fn4">
<p>My favourite paper on the analysis of the worm is <a href="http://denninginstitute.com/modules/acmpkp/security/texts/INTWORM.PDF" target="_blank">With Microscope and Tweezers</a> from MIT&rsquo;s Eichin and Rochlis. They spend a page passionately arguing that it&rsquo;s a virus by using a complicated appeal to the difference between lytic and lysogenic viruses with references to three separate biology textbooks!&nbsp;<a href="#fnref4" rev="footnote">&#8617;</a></p>
</li>

<li id="fn5">
<p>I assumed that <code>/etc/shadow</code> came about as a consequence of the Morris Worm, but it <a href="https://en.wikipedia.org/wiki/Passwd#History" target="_blank">seems</a> that it was originally implemented in SunOS earlier in the 80&rsquo;s, and then took 2 years after the Morris Worm to make it into BSD.&nbsp;<a href="#fnref5" rev="footnote">&#8617;</a></p>
</li>

<li id="fn6">
<p>Exploits really are magic, and it goes without saying that exploit users have chosen the <a href="https://en.wikipedia.org/wiki/Left-hand_path_and_right-hand_path" target="_blank">Left-Hand Path</a> to wizardhood. If the <a href="https://mitpress.mit.edu/sicp/full-text/book/book.html" target="_blank">cover of SICP</a> is to be believed, the Right-Hand Path is available through careful study of functional programming and Lisps. Perhaps this is the true reason why Morris and Graham were such effective collaborators.&nbsp;<a href="#fnref6" rev="footnote">&#8617;</a></p>
</li>

<li id="fn7">
<p>On the other hand, this C code is over 30 years old. When I ran it through the gcc on my machine,I was very happy to see that it complained bitterly but still compiled it. One exercise for the reader is finding where the network operation actually happens. <code>main</code> takes input and output from STDIN/STDOUT, but there&rsquo;s an uninitialized <code>struct sockaddr_in sin</code> that we call <code>getpeername</code> on. How is a network socket piped to standard input/output and who is initializing the <code>sin</code> struct? I actually haven&rsquo;t been able to figure this part out. If you know, please tell <a href="mailto:max@appcanary.com">me</a>! The full code listing is <a href="http://minnie.tuhs.org/cgi-bin/utree.pl?file=4.3BSD/usr/src/etc/fingerd.c" target="_blank">here</a>.&nbsp;<a href="#fnref7" rev="footnote">&#8617;</a></p>

<p><strong>Update 08/29/2016</strong> Dave Vandervies emailed me with an explanation!</p>

<blockquote>
<p>fingerd was meant to be run from inetd (see <a href="http://minnie.tuhs.org/cgi-bin/utree.pl?file=4.3BSD/etc/inetd.conf" target="_blank">here</a>),
which sets up the network connection and invokes the actual server process
with its stdin and stdout attached to the network socket.</p>

<p><br/>
As for the getpeername, the address is an out parameter; this call looks up
the peer address of stdin (fd 0), and will fail (and fingerd will error out
on that) if it isn&rsquo;t a socket (see
<a href="http://man.openbsd.org/OpenBSD-current/man2/getpeername.2">here</a>).
Since the actual address doesn&rsquo;t get used, that appears to be the purpose of the
call here.</p>
</blockquote>
</li>

</ol>
</div>

</section>
<footer class='post-meta'>
<a href='/author/max-veytsman.html'>Max Veytsman</a>
on <a href='/tag/vihkal.html'>vihkal</a>, <a href='/tag/security.html'>security</a>
<time class='post-date' datetime='2016-08-24'>
24 August 2016
</time>
</footer>
</article>
<article class='post'>
<header class='post-header'>
<h1 class='post-title'><a href="../2016/vikhal-symantec.html">Vulnerabilities I Have Known and Loved #1: Symantec's Bad Week</a></h1>
<section class='post-meta'>
</section>
</header>
<section class='post-content'>
<p><strong>tl;dr:</strong> If you use software with &ldquo;Symantec&rdquo; or &ldquo;Norton&rdquo; somewhere in its name, <strong>stop what you&rsquo;re doing and <a href="https://www.symantec.com/support-center/upgrades">upgrade</a></strong>.</p>

<p>Back in my security consulting days, a mentor taught me One Weird Trick to
increase conversions on your phishing campaign.  It goes like this: set up an email server, get as many employee addresses you can find, and spoof a mass message that reads:</p>

<blockquote>
<p>Hello this is your boss. </p>

<p>I&rsquo;m going to fire someone next week and you get to vote on who! To get your arch-nemisis fired, please log into this website that looks exactly like our company portal, but has one character in the domain name mispelled. </p>

<p>Thanks, Your Boss.</p>
</blockquote>

<p>Then you sit back and count how many people fell for it.</p>

<p>The executive who hired you is happy because they get to demonstrate the value of increasing their
security budget. The consultancy you work for is happy, because they get to upsell a bunch of &ldquo;security awareness
training&rdquo;. </p>

<p>Soon, you&rsquo;ll be spending three days telling your victims about the
importance of that little green lock in their browser&rsquo;s address bar (but only
when it&rsquo;s in the right place!) and that they should never ever click on links,
never open attachments, and if at all possible, stop using computers altogether. Everybody wins.</p>

<p>Obviously, everyone at this stage wants to increase the conversion rate<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup> of these phishing emails. This is where The One Weird Trick comes in: after you send out your first campaign, you craft another one. Before you know it, everyone on your list receives a helpful tip from the IT Helpdesk:</p>

<blockquote>
<p>Hi, </p>

<p>We&rsquo;ve heard reports of a phishing campaign being waged against us. Don&rsquo;t open those emails! It&rsquo;s critically important that you reset your password to protect against those evil hackers who tried to phish us. </p>

<p>Click here to do it!</p>
</blockquote>

<p>It turns out that round two gets <em>way</em> more clicks than round one. Most people will figure out that email #1 is a little fishy. Email #2 manages to reaffirm that, and so they dutifully click, like lambs to slaughter.</p>

<p>This is the phishing equivalent of the Double Tap. No, not the one from <a href="https://www.youtube.com/watch?v=w4sWxsrEFFs">Zombieland</a>. The Double Tap I&rsquo;m talking about is a controversial <a href="http://www.businessinsider.com/drone-double-tap-first-responders-2012-9">military technique</a> where after attacking a target, you follow up by sending another missile at the first responders. You do some damage, and then attack the response to that damage.</p>

<h3>Symantec is Having a Bad Week</h3>

<p>Last week <a href="https://twitter.com/taviso">Tavis Ormandy</a> dropped 8 vulns against every single Symantec/Norton antivirus product. Judging by <a href="http://fortune.com/2016/07/02/symantec-security-irony/">the press</a>, things are <a href="http://www.pcworld.com/article/3089463/security/wormable-flaws-in-symantec-products-expose-millions-of-computers-to-hacking.html">not looking good</a> for them.</p>

<p>You can find a writeup up on the <a href="http://googleprojectzero.blogspot.ca/2016/06/how-to-compromise-enterprise-endpoint.html">Google Project Zero
blog</a>, and the issues for all 8 vulnerabilities can <a href="https://bugs.chromium.org/p/project-zero/issues/list?can=1&amp;q=label%3AVendor-Symantec">be found here</a>. They&rsquo;re all remotely exploitable,<sup id="fnref2"><a href="#fn2" rel="footnote">2</a></sup> and they all should give an attacker remote code execution as root/SYSTEM (and in ring 0 for one of them to boot!)</p>

<p>If you&rsquo;re using a Symantec product I can&rsquo;t stress this enough: <strong>stop what you&rsquo;re doing and <a href="https://www.symantec.com/support-center/upgrades">upgrade</a></strong>.</p>

<p>These vulnerabilities reminded me of phishing and the Double Tap for two reasons. First, every one of these vulns can be exploited by just sending an email. Since the product is an antivirus, so it&rsquo;s going to scan every file that touches your disk and every email you get for viruses. You don&rsquo;t have to get your target to click a link or even open the message you sent &mdash; Symantec will happily try to parse every email you receive. </p>

<p>Second, the <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=823&amp;can=1&amp;q=label%3AVendor-Symantec">stack overflow in Symantec&rsquo;s PowerPoint parser</a> depends on a Double Tap-like attack! This parser is used to extract metadata and macros from PowerPoint decks (and presumably scan them for known malware) by exposing an I/O abstraction layer &mdash; which it then caches for performance. Tavis found that he could get that cache into a misaligned state, which resulted in the stack buffer overflow. </p>

<p>This vulnerable codepath is in something called “Bloodhound Heuristics”, which Symantec promotes as a more advanced set of malware detection checks. Since they&rsquo;re not always run, you&rsquo;d think that the vulnerability wouldn&rsquo;t be very exploitable. And yet, it can be targetted every time! Under the default configuration, the system dynamically decides which set of checks to run. All Tavis had to do was try a bunch of known PowerPoint malware, see which one triggered the automatic mode to turn on &ldquo;Bloodhound Heuristics,&rdquo; and put his payload into them.</p>

<p>The exploit pretends to be a certain kind of known malware in order to trigger some special aggressive checks, which are the exploit&rsquo;s true target. The Double Tap!</p>

<h3>Vulnerability Management</h3>

<p>While the above vulnerability is pretty cool, the Symantec bugs that are most interesting to us at Appcanary are <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=810">CVE-2016-2207</a> and <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=816">CVE-2016-2211</a>. </p>

<p>Symantec was shipping its product with out of date versions of <a href="http://www.cabextract.org.uk/libmspack/">libmspack</a> and <a href="http://www.rarlab.com/rar_add.htm">unrarsrc</a>. Out of date versions that have dozens of known vulnerabilities with public exploits! All Tavis had to do was download public exploits for these known vulnerabilities, and he had an attack against Symantec.</p>

<p>Ironically, Symantec sells a product called Enterprise Vulnerability Management! This is a hard problem for everyone. At Appcanary, we&rsquo;re working on solving it.</p>

<h3>P.S.</h3>

<p><link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
 #mc<em>embed</em>signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}
 /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
      We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//appcanary.us10.list-manage.com/subscribe/post?u=303b378f377508300c0b5469a&amp;id=dc58e8f56f" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
<div id="mc_embed_signup_scroll">
<label for="mce-EMAIL">Liked this post? Subscribe to our newsletter for more!</label>
<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
<div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_303b378f377508300c0b5469a_dc58e8f56f" tabindex="-1" value=""></div>
<div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
</div>
</form>
</div></p>

<p>Do you have suggestions for vulnerabilities you&rsquo;d like me to write about? You can let me know at <a href="mailto:max@appcanary.com">max@appcanary.com</a>.</p>

<hr>

<h4>Paying the Bills</h4>

<p>One quarter of the critical vulnerabilities found in Symantec&rsquo;s products last week were there because they relied on out-of-date libraries with known security holes.</p>

<p>Our product, <a href="https://appcanary.com/?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=symantec">Appcanary</a>, monitors your apps and servers, and notifies you whenever a new vulnerability is discovered in a package you rely on. </p>

<p><a href="https://appcanary.com/sign_up?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=symantec">Sign up</a> today!</p>

<div class="footnotes">
<hr>
<ol>

<li id="fn1">
<p>You know, it&rsquo;s interesting that before I became the CEO of a startup, the only time I thought about &ldquo;conversion rates&rdquo; of emails in my career was when I was involved in phishing campaigns.&nbsp;<a href="#fnref1" rev="footnote">&#8617;</a></p>
</li>

<li id="fn2">
<p>I&rsquo;m going to well-actually myself here so you don&rsquo;t have to. Tavis gives a clear path to exploit for 6 of the 8. Of the two that are left, <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=821">one</a> is a lack of bounds checking on an array index, and the <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=819">other</a> is an integer overflow bug. I&rsquo;m going to go out on a limb and say I think both can lead to code execution. I can&rsquo;t fault the researcher for not going further though; after you find the first 6 remote code executions, you stop feeling the need to keep proving the point&hellip;&nbsp;<a href="#fnref2" rev="footnote">&#8617;</a></p>
</li>

</ol>
</div>

</section>
<footer class='post-meta'>
<a href='/author/max-veytsman.html'>Max Veytsman</a>
on <a href='/tag/vihkal.html'>vihkal</a>, <a href='/tag/security.html'>security</a>
<time class='post-date' datetime='2016-07-07'>
07 July 2016
</time>
</footer>
</article>
<article class='post'>
<header class='post-header'>
<h1 class='post-title'><a href="../2016/encrypt-or-compress.html">Should you encrypt or compress first?</a></h1>
<section class='post-meta'>
</section>
</header>
<section class='post-content'>
<p>Imagine this:</p>

<p>You work for a big company. Your job is pretty boring. Frankly, your talents are wasted writing boilerplate code for an application whose only users are three people in accounting who can&rsquo;t stand the sight of you.</p>

<p>Your real passion is security. You read <a href="https://www.reddit.com/r/netsec">r/netsec</a> every day and participate in bug bounties after work. For the past three months, you&rsquo;ve been playing a baroque stock trading game that you&rsquo;re winning because you found a heap-based buffer overflow and wrote some AVR shellcode to help you pick stocks.</p>

<p>Everything changes when you discover that what you had thought was a video game was actually a cleverly disguised recruitment tool. Mont Piper, the best security consultancy in the world, is hiring &mdash; and you just landed an interview!</p>

<p>A plane ride and an Uber later, you&rsquo;re sitting across from your potential future boss: a slightly sweaty hacker named Gary in a Norwegian metal band t-shirt and sunglasses he refuses to take off indoors.</p>

<p>You blast through the first part of the interview. You give a great explanation of the difference between privacy and anonymity. You describe the same origin policy in great detail, and give three ways an attacker can get around it. You even whiteboard the intricacies of <code>__fastcall</code> vs <code>__stdcall</code>. Finally, you&rsquo;re at the penultimate section, protocol security.</p>

<p>Gary looks you in the eyes and says: &ldquo;You&rsquo;re designing a network protocol. Do you compress the data and then encrypt it, or do you encrypt and then compress?&rdquo; And then he clasps his hands together and smiles to himself.</p>

<p>A classic security interview question!</p>

<hr>

<p>Take a second and think about it. </p>

<p>At a high level, compression tries to use patterns in data in order to reduce its size. Encryption tries to shuffle data in such a way that without the key, you can&rsquo;t find any patterns in the data at all. </p>

<p>Encryption produces output that appears random: a jumble of bits with a lot of entropy. Compression doesn&rsquo;t really work on data that appears random &mdash; entropy can actually be thought of as a measure of how &ldquo;compressable&rdquo; some data is.</p>

<p>So if you encrypt first, your compression will be useless. The answer must be to compress first! Even StackOverflow <a href="http://stackoverflow.com/questions/4676095/when-compressing-and-encrypting-should-i-compress-first-or-encrypt-first">thinks so</a>.</p>

<hr>

<p>You start to say this to Gary, but you stop mid-sentence. An attacker sniffing encrypted traffic doesn&rsquo;t get much information, but they do get to learn the length of messages. If they can somehow use that to learn more information about the message, maybe they can foil the encryption.</p>

<p>You start explaining this to Gary, and he interrupts you &mdash; &ldquo;Oh you mean like the <a href="https://www.nccgroup.trust/us/about-us/newsroom-and-events/blog/2012/september/details-on-the-crime-attack/">CRIME</a> attack?&rdquo;</p>

<p>&ldquo;Yes!&rdquo; you reply. You start to recall the details of it. All the SSL attacks with catchy names are mixed together in your mind, but you&rsquo;re pretty sure that&rsquo;s the one. They controlled some information that was being returned by the server, and used that to generate guesses for a secret token present in the response. The response was compressed in such a way that you could validate guesses for the secret by seeing how you affected the length of the compressed message. If the secret was <code>AAAA</code> and you guessed <code>AAAA</code>, the compressed-then-encrypted response will be shorter than if you guessed <code>BBBB</code>.</p>

<p>Gary looks impressed. &ldquo;But what if the attacker can&rsquo;t control any of the plaintext in any way? Is this kind of attack still possible?&rdquo; he asks.</p>

<hr>

<p>CRIME was a very cool demonstration of how compress-then-encrypt isn&rsquo;t always the right decision, but my favorite compress-then-encrypt attack was published a year earlier by Andrew M. White, Austin R. Matthews, Kevin Z. Snow, and Fabian Monrose. The paper <a href="http://www.cs.unc.edu/~fabian/papers/foniks-oak11.pdf">Phonotactic Reconstruction of Encrypted VoIP Conversations</a> gives a technique for reconstructing speech from an encrypted VoIP call.</p>

<p>Basically, the idea is this: VoIP compression isn&rsquo;t going to be a generic audio compression algorithm, because we can rely on some assumptions about human speech in order to compress more efficiently. From the paper:</p>

<blockquote>
<p>Many modern speech codecs are based on variants of a well-known speech coding
scheme known as code-excited linear prediction (CELP) [49], which is in turn
based on the source-filter model of speech prediction. The source-filter model
separates the audio into two signals: the excitation or source signal, as
produced by the vocal cords, and the shape or filter signal, which models the
shaping of the sound performed by the vocal tract. This allows for
differentiation of phonemes; for instance, vowels have a periodic excitation
signal while fricatives (such as the [sh] and [f] sounds) have an excitation
signal similar to white noise [53].</p>

<p>In basic CELP, the excitation signal is modeled as an entry
from a fixed codebook (hence code-excited). In some CELP
variants, such as Speex’s VBR (variable bit rate) mode, the codewords can
be chosen from different codebooks depending on the complexity
of the input frame; each codebook contains entries
of a different size. The filter signal is modeled using linear
prediction, i.e., as a so-called adaptive codebook where the
codebook entries are linear combinations of past excitation
signals. The “best” entries from each codebook are chosen
by searching the space of possible codewords in order
to “perceptually” optimize the output signal in a process
known as analysis-by-synthesis [53]. Thus an encoded frame
consists of a fixed codebook entry and gain (coefficient) for
the excitation signal and the linear prediction coefficients for
the filter signal.</p>

<p>Lastly, many VoIP providers (including Skype) use VBR 
codecs to minimize bandwidth usage while maintaining
call quality. Under VBR, the size of the codebook entry,
and thus the size of the encoded frame, can vary based
on the complexity of the input frame. The specification
for Secure RTP (SRTP) [3] does not alter the size of the
original payload; thus encoded frame sizes are preserved
across the cryptographic layer. The size of the encrypted
packet therefore reflects properties of the input signal; it is
exactly this correlation that our approach leverages to model
phonemes as sequences of lengths of encrypted packets.</p>
</blockquote>

<p>That pretty much summarizes the paper. CELP + VBR means that message length is going to depend on complexity. Due to how linear prediction works, more information is needed to encode a drastic change in sound &mdash; like the pause between phonemes! This allows the authors to build a model that can break an <strong>encrypted</strong> audio signal into phonemes: that is, deciding which audio frames belong to which unit of speech.</p>

<p>They then built a classifier that, still only using the packet length information they started with, decides which segmented units of encrypted audio represent which actual phonemes. They then use a language model to correct the previous step&rsquo;s output and segment the phoneme stream into words and then phrases.</p>

<p>The crazy thing is that this whole rigmarole works! They used a metric called <a href="http://www.cs.cmu.edu/~alavie/METEOR/">METEOR</a> and got scores of around .6. This is on a scale where &lt;.5 is considered &ldquo;interpretable by a human.&rdquo; Considering that the threat vector here is a human using this technique to listen in on your encrypted VoIP calls &mdash; that&rsquo;s pretty amazing! </p>

<hr>

<h2>Epilogue</h2>

<p>After passing the rigorous all-night culture fit screening, you end up getting the job. Six months later, Mont Piper is sold to a large conglomerate. Gary refuses to trade in his Norwegian metal t-shirts for a button-down and is summarily fired. You now spend your days going on-site to a big bank, &ldquo;advising&rdquo; a team that hates your guts.</p>

<p>But recently, you&rsquo;ve picked up machine learning and found this really cool online game where you try to make a 6-legged robot walk in a 3d physics simulation&hellip;</p>

<hr>

<h3>P.S.</h3>

<p><link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
 #mc<em>embed</em>signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}
 /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
      We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//appcanary.us10.list-manage.com/subscribe/post?u=303b378f377508300c0b5469a&amp;id=dc58e8f56f" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
<div id="mc_embed_signup_scroll">
<label for="mce-EMAIL">Liked this post? Subscribe to our newsletter for more!</label>
<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
<div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_303b378f377508300c0b5469a_dc58e8f56f" tabindex="-1" value=""></div>
<div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
</div>
</form>
</div></p>

<hr>

<h4>Paying the Bills</h4>

<p>Vulnerabilities come out every day, and most don&rsquo;t get blog posts like this written about them.</p>

<p>Our product, <a href="https://appcanary.com/?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=compress">Appcanary</a>, monitors your apps and servers, and notifies you whenever a new vulnerability is discovered in a package you rely on. </p>

<p><a href="https://appcanary.com/sign_up?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=compress">Sign up</a> today!</p>

</section>
<footer class='post-meta'>
<a href='/author/max-veytsman.html'>Max Veytsman</a>
on <a href='/tag/security.html'>security</a>, <a href='/tag/crypto.html'>crypto</a>
<time class='post-date' datetime='2016-06-25'>
25 June 2016
</time>
</footer>
</article>
<nav class='pagination' role='pagination'>
<span class='page-number'>Page 1 of 1</span>
</nav>


</main>

<footer class='site-footer clearfix'>
<section class='copyright'>
<a href='/'>Appcanary</a>
&copy;
2016
</section>
<section class='poweredby'>
</section>
</footer>
</div>
<script src="../javascripts/application.js"></script>
<script type="text/javascript">
 /* <![CDATA[ */
 var google_conversion_id = 928841383;
 var google_custom_params = window.google_tag_params;
 var google_remarketing_only = true;
 /* ]]> */
</script>

<script type="text/javascript" src="//www.googleadservices.com/pagead/conversion.js">
</script>
<noscript>
    <div style="display:inline;">
        <img height="1" width="1" style="border-style:none;" alt="" src="//googleads.g.doubleclick.net/pagead/viewthroughconversion/928841383/?value=0&amp;guid=ON&amp;script=0"/>
    </div>
</noscript>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-61163522-3', 'auto');
  ga('send', 'pageview');

</script>

</body>
</html>
